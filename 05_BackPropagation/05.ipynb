{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd961fda-f2e4-4cb3-97e2-f8236c4179ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7c63ec-529a-490f-8525-6b3282b3c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('../names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adef1f6c-6503-4199-a475-6fa4eb9436ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77de77de-83e4-40ea-a0ab-dd9afc7e25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the datatset\n",
    "block_size = 3 # context_length how many words you want to use to predict the next one\n",
    "\n",
    "def build_dataset(words):\n",
    "    X,Y = [],[]\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] #Leave the first ch and append the Y in context\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dde0d9-f244-4189-b788-c138cf6d7751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2294b714-dc8f-4ad6-8da5-9f6725b5a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ff2f68-a5b9-4bee-8878-c3f6f560f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1393484e-971e-4f54-9697-726e7e8a30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([120000, 157809,  82137,  69514,  73004,  68734,    286, 123947,  13538,\n",
      "         42674, 165010,  81021,  59151,  46471,  62456,  64636,  24418, 108817,\n",
      "        169833, 145683, 168275, 157689,  36258, 142280,  32537, 149713, 149734,\n",
      "        149517, 165139, 153533,  89661,  20039])\n",
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14],\n",
      "        [ 0, 17,  1],\n",
      "        [ 0,  0, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 8, 25, 12],\n",
      "        [ 0,  0, 26],\n",
      "        [22, 15, 14],\n",
      "        [19, 13,  9],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  4,  5],\n",
      "        [ 5, 14,  9],\n",
      "        [18,  5,  5],\n",
      "        [ 0,  4,  1],\n",
      "        [ 1, 18,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  5, 12],\n",
      "        [ 0, 10,  1],\n",
      "        [ 9, 14,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 18],\n",
      "        [20,  5,  1],\n",
      "        [ 0, 11, 15],\n",
      "        [ 0,  0,  7],\n",
      "        [ 0, 18,  5],\n",
      "        [26,  5, 18],\n",
      "        [ 0,  0, 14],\n",
      "        [ 3,  5, 14],\n",
      "        [ 0, 18, 15]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "ix = torch.randint(0,Xtr.shape[0],(batch_size,),generator=g) # generates a batch_size with 32 rows\n",
    "print(ix)\n",
    "Xb,Yb = Xtr[ix], Ytr[ix]\n",
    "print(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c54dcb73-1a39-41e3-b29c-cd029b44c9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3235, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "emb = C[Xb] # 32,3,10\n",
    "embcat = emb.view(emb.shape[0],-1) # 32,10\n",
    "#Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "#Batch Norm Layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True) # calculates the mean values across the batch dimension and normalizes it\n",
    "bndiff = hprebn - bnmeani # mean centering\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # This sums the squared deviations along the batch dimension (axis 0)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv # Each feature has 0 mean and unit varinace\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values # extracts the maximum value of logits across classes dimension(along row)\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f7f1bc-1e30-44d1-9957-dd72a8c2592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logprobs[range(n), Yb] # advanced indexing to select the log-probability of the correct class for each sample depending on Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b7067c-acc4-420f-b6b8-3447398a55cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2523f944-384c-4e23-a6d7-caae275546dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape # The non-participating elements of logprobs is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123a4d05-117a-4530-83fc-142ed81e756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0709, -3.0870, -3.7171, -3.3796, -4.1653, -3.6182, -3.0707, -4.0054,\n",
       "        -3.1616, -4.3117, -3.1610, -1.7220, -2.7403, -2.9918, -2.9891, -3.2731,\n",
       "        -3.8096, -2.9677, -3.5106, -3.3395, -2.8717, -3.0400, -4.2327, -4.0171,\n",
       "        -3.5698, -2.9559, -2.9219, -3.9742, -2.7591, -3.3596, -3.3573, -3.1317],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb] # The value of 8th column at 0th row is -4.0589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d771d9f-a612-4b41-8efa-e443137327b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -(a+b+c)/3\n",
    "# dloss/da = -1/3 if we have more numbers it is going to be -1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7061306-0eba-4a95-a819-188ed2ee2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs',dlogprobs,logprobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f5d53e5-7c9d-4c8b-afac-b6d438b9e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dprobs = (1/probs) * dlogprobs #low probability gradient boost\n",
    "cmp('probs',dprobs,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782b19cf-b342-4628-bbaf-3fc1f36a2e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape,counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1902ab5-19a1-48f1-aaa3-c84fadab6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b\n",
    "# a[3X3] * b [3,1]\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b2\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "#c[3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5f66a0-cc27-425b-bc1d-9438890a98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#probs = counts * counts_sum_inv\n",
    "#dprobs/dcounts_sum_inv = counts\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1,keepdim=True) # broadcasting happens so sum\n",
    "cmp('counts_sum_inv',dcounts_sum_inv,counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bed2fd54-ebaa-4e9c-92eb-46146adb45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs # 32,1 32,27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b5b1242-6e18-45b7-8407-c15d6b098c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = (-1*counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825c1c6b-cff1-49a3-bf56-116a97640842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape,counts_sum.shape\n",
    "# a11 a12 a13 ... a1,27         - b1 = (sum of all a1 rows)\n",
    "# a21 a22 a23 ... b2,27         - b2 = (sum of all a2 rows)\n",
    "# a32,1 a32,2 a32,3 ...a32,17   - b32 = (sum of all a32 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f95a03-72e2-4b30-8fa0-e7e0d2aeca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbb0ca7-4bf6-417d-b2cf-df0a1cf476d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5c4c5-1606-4f99-9a63-cd3cf308c047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee8aafc4-278c-4107-bffd-652e738c6b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape,logits.shape,logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa348d2d-916b-47ea-a8bb-2df6449da13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c32 = a32 - b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8212bf9c-286d-43b4-90c6-14b726235991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1,keepdim=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e480f03-c9f4-44c1-aeac-688019091336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dlogit_maxes # logit maxes do not impact loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2a12120-ec5f-4ac6-b2ea-22722ff726a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126b9a2d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#logits.max(1,keepdim=True)\n",
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e300beb-23a7-431f-935c-3c4ee3f8891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9196ae03-c11f-4d03-8fed-315afd83fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape,h.shape,W2.shape,b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "912cf636-133d-405e-a7eb-a1bed6951b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h@w1 = (32,27) and b2 = (27)\n",
    "# so b2 broadcasts into (1,27) and this (1,27) replicates vertically 32 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8460a521-ee2f-4d6f-8a5d-7929fd297c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dh = dlogits @ W2.T\n",
    "cmp('h', dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20418cef-78b1-4bbd-8c58-fdab07f446ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dW2 = h.T @dlogits \n",
    "cmp('W2', dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c2ab0e5-9c9d-43f7-ac89-51c6c49b24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19101862-62c1-405a-a4d5-e1a23864372c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9519f78c-5b48-4778-96ee-0c0353b98b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dhpreact = (1.0 - h ** 2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebd207e0-13c7-4a9b-8131-10f511b636c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bngain.shape,bnraw.shape,bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "011308d1-5cec-43c2-94e1-494202e76cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbngain = (bnraw * dhpreact ).sum(0,keepdim=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "dbnraw = (bngain * dhpreact)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "dbnbias = dhpreact.sum(0,keepdim=True)\n",
    "cmp('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a716517-fd40-4962-b295-06d8711e58ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape,bndiff.shape,bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fb6e255-2da0-45a2-96b8-7740b8b4cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbndiff = (bnvar_inv * dbnraw)\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0,keepdim=True)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c56cf9b8-e28d-48dc-abc2-8e0e484faf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58d6fd0b-8b19-4f01-82d8-c27c9e814894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
    "bnvar.shape,bndiff2.shape\n",
    "#a11 a12\n",
    "#a21 a22\n",
    "# -- >\n",
    "#b1 and b2 where:\n",
    "#b1 = 1/(n-1) * (a11 + a12)\n",
    "#b2 = 1/(n-1) * (a21 + a22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d73e2969-e632-4288-a3fe-626a5c340de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbndiff2 = ((1.0/(n-1))*torch.ones_like(bndiff2)) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43f10246-ddf4-4cb8-b0bd-7fcfc263dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#bndiff2 = bndiff**2\n",
    "dbndiff += 2 * bndiff * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea41183a-8e29-4e62-8f10-59e8bee5606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bndiff = hprebn - bnmeani\n",
    "bndiff.shape,hprebn.shape,bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07618a0c-4a94-4434-845a-09e53b8e0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbnmeani = (-1.0 * dbndiff).sum(0,keepdim=True) # \n",
    "cmp('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b7b6697-5d02-4c59-b19b-c655fe726d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: False | maxdiff: 0.001072533312253654\n"
     ]
    }
   ],
   "source": [
    "dhprebn = dbndiff.clone() * 1.0\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b294415f-02e8-4208-bfc8-30308569aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "dhprebn += (1.0/n) * (dbnmeani * torch.ones_like(hprebn))\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4593155f-fbc6-4211-b3f3-a80e6791f914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([32, 64]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hprebn = embcat @ W1 + b1 \n",
    "hprebn.shape,embcat.shape,W1.shape,b1.shape,dhprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fe4cf53-81be-48fb-a3b1-3f9dea553b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dembcat = (dhprebn @ W1.T)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48c50f19-0aaf-435e-b2ca-660d15e398fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14]])\n"
     ]
    }
   ],
   "source": [
    "# emb = C[Xb] # 32,3,10\n",
    "# embcat = emb.view(emb.shape[0],-1)\n",
    "embcat.shape,emb.shape,C.shape,Xb.shape\n",
    "print(Xb[:5]) # which row of C to pluck out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0be526ac-ef09-4a63-b57d-dfd831032b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "demb  = dembcat.view(emb.shape)\n",
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb39ef37-01bf-4687-9d9a-631c26646796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f32fe6a8-adbb-44f8-8dcb-42eebb27b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmp('logprobs', dlogprobs, logprobs)\n",
    "# cmp('probs', dprobs, probs)\n",
    "# cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "# cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "# cmp('counts', dcounts, counts)\n",
    "# cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "# cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "# cmp('logits', dlogits, logits)\n",
    "# cmp('h', dh, h)\n",
    "# cmp('W2', dW2, W2)\n",
    "# cmp('b2', db2, b2)\n",
    "# cmp('hpreact', dhpreact, hpreact)\n",
    "# cmp('bngain', dbngain, bngain)\n",
    "# cmp('bnbias', dbnbias, bnbias)\n",
    "# cmp('bnraw', dbnraw, bnraw)\n",
    "# cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "# cmp('bnvar', dbnvar, bnvar)\n",
    "# cmp('bndiff2', dbndiff2, bndiff2)\n",
    "# cmp('bndiff', dbndiff, bndiff)\n",
    "# cmp('bnmeani', dbnmeani, bnmeani)\n",
    "# cmp('hprebn', dhprebn, hprebn)\n",
    "# cmp('embcat', dembcat, embcat)\n",
    "# cmp('W1', dW1, W1)\n",
    "# cmp('b1', db1, b1)\n",
    "# cmp('emb', demb, emb)\n",
    "# cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73b1c0a0-a584-4c23-9ffe-b39dcabb45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bessels correction in batchNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "265b6da8-a824-4d07-9ced-5996e7332dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3525962829589844 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "235d649d-14af-4670-9245-94fd54172ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 7.683411240577698e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "dlogits = F.softmax(logits,1)\n",
    "dlogits[range(n),Yb] -=1\n",
    "dlogits /= n\n",
    "# -----------------\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb70c8c6-fe22-48b8-928e-70407f146c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67f653ec-15cb-4e1b-9859-20bb656f0ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0693, 0.0868, 0.0194, 0.0505, 0.0193, 0.0811, 0.0223, 0.0372, 0.0171,\n",
       "        0.0311, 0.0375, 0.0361, 0.0390, 0.0296, 0.0341, 0.0129, 0.0089, 0.0198,\n",
       "        0.0149, 0.0543, 0.0473, 0.0238, 0.0270, 0.0738, 0.0566, 0.0276, 0.0226],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31d9b6ae-7127-4fa3-865e-fb98924aaed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0022,  0.0027,  0.0006,  0.0016,  0.0006,  0.0025,  0.0007,  0.0012,\n",
       "        -0.0307,  0.0010,  0.0012,  0.0011,  0.0012,  0.0009,  0.0011,  0.0004,\n",
       "         0.0003,  0.0006,  0.0005,  0.0017,  0.0015,  0.0007,  0.0008,  0.0023,\n",
       "         0.0018,  0.0009,  0.0007], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87edfaed-d3e0-4fce-b42e-16a158b2df9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0693,  0.0868,  0.0194,  0.0505,  0.0193,  0.0811,  0.0223,  0.0372,\n",
       "        -0.9829,  0.0311,  0.0375,  0.0361,  0.0390,  0.0296,  0.0341,  0.0129,\n",
       "         0.0089,  0.0198,  0.0149,  0.0543,  0.0473,  0.0238,  0.0270,  0.0738,\n",
       "         0.0566,  0.0276,  0.0226], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d0d87b3-ae3b-417f-89eb-6be23fc0723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.1223e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb1fc284-28a3-404d-acd3-a015bc641e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126c3fc10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8d060-0923-4691-80e9-8ca236df520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogits refers to the probabilties matrix in the forward pass.\n",
    "# The black refers to the correct indices.\n",
    "# The force which pulls down probs of incorrect and pull up the probs of correct. The force is directly proportional to probabilites \n",
    "# came out in the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13a5ceca-0494-4702-9430-deed9b0c64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a9cbc02-c154-49cc-9625-0934bfa66d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "dhprebn = None # TODO. my solution is 1 (long) line\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "# -----------------\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc59f981-f9fe-4d03-afb9-874256ec639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7729\n",
      "  10000/ 200000: 2.1874\n",
      "  20000/ 200000: 2.3926\n",
      "  30000/ 200000: 2.4312\n",
      "  40000/ 200000: 1.9744\n",
      "  50000/ 200000: 2.3155\n",
      "  60000/ 200000: 2.4311\n",
      "  70000/ 200000: 2.0831\n",
      "  80000/ 200000: 2.3176\n",
      "  90000/ 200000: 2.1535\n",
      " 100000/ 200000: 2.0058\n",
      " 110000/ 200000: 2.3770\n",
      " 120000/ 200000: 1.9886\n",
      " 130000/ 200000: 2.4161\n",
      " 140000/ 200000: 2.2826\n",
      " 150000/ 200000: 2.1692\n",
      " 160000/ 200000: 1.9258\n",
      " 170000/ 200000: 1.8513\n",
      " 180000/ 200000: 2.0236\n",
      " 190000/ 200000: 1.8597\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190daf6d-bb72-40cc-814c-ddbc165a55d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c05a3-8656-438a-9319-00e3b0113a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
